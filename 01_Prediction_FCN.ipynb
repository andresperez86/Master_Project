{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01. Prediction_FCN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOaddgttCQ+7w7fzk8fbxvJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeF0_qVt2YAp"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-vDlAkW2syf",
        "outputId": "18ee3320-acb1-4274-d3d6-884b5bb9b517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwJ37BI22w65"
      },
      "source": [
        "download = drive.CreateFile({'id': '15OCV9UbTR7k8ks-TDcC93r3bjhrG3xvo'})\n",
        "download.GetContentFile('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoE66C4-20vd"
      },
      "source": [
        "#for download the dataset\n",
        "# Please fill the ... with the id of Dataset_JPV.zip in the google drive\n",
        "\n",
        "download = drive.CreateFile({'id': '15OCV9UbTR7k8ks-TDcC93r3bjhrG3xvo'})\n",
        "download.GetContentFile('Dataset_JPV.zip')\n",
        "download.GetContentFile('my_model.zip')\n",
        "\n",
        "#!unzip rotated_3100.zip there is not file with that named"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCu4nyvAbGqi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdPkpRIHL87O"
      },
      "source": [
        "# unzip your file\n",
        "!unzip -o Dataset_JPV.zip -d Dataset_JPV > /dev/null\n",
        "!unzip -o my_model.zip -d my_model > /dev/null\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRrpVXTt3MV7"
      },
      "source": [
        "# load data func\n",
        "import glob\n",
        "from keras.preprocessing import image as kImage\n",
        "\n",
        "def getData(dataset_dir):\n",
        "    X_list= sorted(glob.glob(os.path.join(dataset_dir, 'x','*.jpg')))\n",
        "    Y_list = sorted(glob.glob(os.path.join(dataset_dir, 'y' ,'*.png')))\n",
        "    \n",
        "    X= []\n",
        "    Y= []\n",
        "    for i in range(len(X_list)):\n",
        "        # Load input image\n",
        "        x = kImage.load_img(X_list[i])\n",
        "        x = kImage.img_to_array(x)\n",
        "        X.append(x)\n",
        "        \n",
        "        # Load ground-truth label and encode it to label 0 and 1\n",
        "        y = kImage.load_img(Y_list[i], color_mode = \"grayscale\")#grayscale = True)\n",
        "        y = kImage.img_to_array(y)\n",
        "        y /= 255.0\n",
        "        y = np.floor(y)# ?\n",
        "        Y.append(y)\n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "    \n",
        "    # Shuffle the training data\n",
        "    idx = list(range(X.shape[0]))\n",
        "    np.random.shuffle(idx)\n",
        "    X = X[idx]\n",
        "    Y = Y[idx]\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8ACFmsfd4li"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmxGNNwmf6MS"
      },
      "source": [
        "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
        "checkpointer = ModelCheckpoint('my_mdel.h5', verbose=1, save_best_only=True)\n",
        "#results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n",
        "                    callbacks=[earlystopper, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J3fC1GYgsVC",
        "outputId": "56367ac3-4e5f-4774-ac34-ab53741d38ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "checkpointer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.ModelCheckpoint at 0x7f2087220a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSJyPk5peZLO",
        "outputId": "93ef13c4-6515-45f6-e897-4c6aee22a134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "model = load_model('my_mdel.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-c6ba151b6489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_mdel.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: my_mdel.h5/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Neq5jKyIb_IT",
        "outputId": "659d01c3-214a-4c59-f581-624c3d1e1410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "dataset_path = os.path.join('Dataset_JPV', 'test')\n",
        "X, Y = getData(dataset_path)\n",
        "# predict\n",
        "pred = model.predict(X, verbose=1, batch_size=1)\n",
        "print(\"Average Test Accuracy for Amir Dataset:\" ,tf.Session().run(K.mean(K.equal(Y, K.round(pred)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-343917a5268c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average Test Accuracy for Amir Dataset:\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI1d3rUM_Zf2"
      },
      "source": [
        "def get_model(num_classes, img_size=320, compile=True):\n",
        "    print(\"using\",num_classes,\"classes\")\n",
        "    inputs = tf.keras.Input(shape=(240,img_size,3), name=\"input_1\")\n",
        "    layers = tf.keras.layers.Conv2D(64,(1,1), activation=\"relu\")(inputs)\n",
        "    layers = tf.keras.layers.Conv2D(64,(1,1), activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.MaxPool2D((2,2))(layers)\n",
        "    layers = tf.keras.layers.Conv2D(128,(1,1), activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Conv2D(128,(1,1), activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.MaxPool2D((2,2))(layers)\n",
        "    layers = tf.keras.layers.Conv2D(256,(1,1), activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Conv2D(256,(1,1), activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.MaxPool2D((2,2))(layers)\n",
        "    layers = tf.keras.layers.Conv2D(512,(1,1), activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Conv2D(512,(1,1), activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.MaxPool2D((2,2))(layers)\n",
        "    layers = tf.keras.layers.Conv2D(512,(1,1), activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Conv2DTranspose(256,(30,40), activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Conv2DTranspose(128,(60,80), activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Conv2DTranspose(64,(120,160), activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Conv2DTranspose(32,(240,320), activation=\"relu\")(layers)\n",
        "    outputs = tf.keras.layers.Conv2DTranspose(1, (1, 1), activation='sigmoid')(layers)\n",
        "    model = tf.keras.Model(inputs = inputs, outputs=outputs)\n",
        "    if compile:\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss='Binary_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAT5ONDUBBOm"
      },
      "source": [
        "def train(model, batch_size, epochs, model_name=\"\"):\n",
        "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\"+model_name+\"_\"+\"{}\".format(time()))\n",
        "    model.reset_states()\n",
        "    model.fit(x_train, y_train, epochs=epochs, callbacks=[tensorboard],\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(x_test, y_test))\n",
        "    metrics = model.evaluate(x_test, y_test)\n",
        "    return {k:v for k,v in zip (model.metrics_names, metrics)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDjZTLANBEiq",
        "outputId": "d0d4daa2-df77-4be8-ce7c-099537a9b067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        }
      },
      "source": [
        "num_classes = 33\n",
        "model = get_model(num_classes)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using 33 classes\n",
            "Model: \"functional_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 240, 320, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_107 (Conv2D)          (None, 240, 320, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 240, 320, 64)      4160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 120, 160, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 120, 160, 128)     8320      \n",
            "_________________________________________________________________\n",
            "conv2d_110 (Conv2D)          (None, 120, 160, 128)     16512     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 60, 80, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_111 (Conv2D)          (None, 60, 80, 256)       33024     \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 60, 80, 256)       65792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 30, 40, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_113 (Conv2D)          (None, 30, 40, 512)       131584    \n",
            "_________________________________________________________________\n",
            "conv2d_114 (Conv2D)          (None, 30, 40, 512)       262656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 15, 20, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_115 (Conv2D)          (None, 15, 20, 512)       262656    \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_15 (Conv2DT (None, 44, 59, 256)       157286656 \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_16 (Conv2DT (None, 103, 138, 128)     157286528 \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_17 (Conv2DT (None, 222, 297, 64)      157286464 \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_18 (Conv2DT (None, 461, 616, 32)      157286432 \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_19 (Conv2DT (None, 461, 616, 1)       33        \n",
            "=================================================================\n",
            "Total params: 629,931,073\n",
            "Trainable params: 629,931,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d-2XVME-fiU"
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBPoseKjlpPW",
        "outputId": "c8f68e33-1a60-454b-c30a-145f7f7d41f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        " \n",
        "# load model\n",
        "model = load_model('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-7be80d4a9760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: my_model.h5/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRveL4jv3crJ",
        "outputId": "f24eb4c5-21dc-4f41-a11b-704f9eb8ae6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "dataset_path = os.path.join('Dataset_JPV', 'test')\n",
        "X, Y = getData(dataset_path)\n",
        "# predict\n",
        "pred = model.predict(X, verbose=1, batch_size=1)\n",
        "print(\"Average Test Accuracy for Amir Dataset:\" ,tf.Session().run(K.mean(K.equal(Y, K.round(pred)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d24154a4ddcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average Test Accuracy for Amir Dataset:\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}